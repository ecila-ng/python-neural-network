{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 03 - Artificial Neural Networks\n",
    "\n",
    "### The following topics are discussed in this notebook:\n",
    "* The architecture of an artificial neural network.\n",
    "* Building neural networks in keras.\n",
    "\n",
    "### Additional Resources\n",
    "* **Deep Learning with Python**, Section 3.4, Pages 68 - 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the previous lesson, logistic regression models (which consist of a single artifial neuron) always result in a linear decision boundary. While that might be appropriate for some problems, there are many problems for which a linear decision boundary will be insufficient. For those types of problems, we will need a more complex model. This can be achieved by stacking individual neurons together into an **artificial neural network**.\n",
    "\n",
    "An ANN consists of many layers of neurons, which are processed in a specific order. There are three types of layers in an ANN: The input layer, one or more hidden layers, and an output layer. \n",
    "\n",
    "* The first layer, called the **input layer**, consist of the features being fed into the model. It contains one node for each feature being used, plus a single bias node. \n",
    "\n",
    "* The output of each node in the input layer is sent to each (non-bias) node in the first **hidden layer**. Every connection between any two pair of nodes in these two layers will have its own weight. The nodes in the first hidden layer process the inputs it recieves from the input layer, and send their outputs downstream to any subsequent hidden layers. \n",
    "\n",
    "* The last hidden layer will send its output to an **output** layer. This output layer could contain one or more neurons, depending on the type of task that the network is being used for. \n",
    "\n",
    "We can build a neural network with as many hidden layers as we wish, and each hidden layer can have as many nodes as we would like. As a general rule, the more neurons that there are in a model, the more flexible that model is. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NNet](Images/03_nnet.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "\n",
    "The first neural network that we will build will be to tackle the following classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(887)\n",
    "X = np.random.uniform(0,1,[300,2])\n",
    "pB = 40*np.abs(X[:,0] - X[:,1])**4\n",
    "pR = np.random.uniform(0,1,300)\n",
    "col = np.where(pB < pR, 'r', 'b')\n",
    "y = np.where(pB < pR, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X[:,0], X[:,1], c=col, edgecolor='k', s=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "\n",
    "We will use keras to build a neural network with one hidden layer, containing four (non-bias) nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Net01](Images/03_net01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras Modules\n",
    "\n",
    "We will be using the Keras package to construct neural networks in this course. Keras provides a high-level API for building neural networks. It is built on top of TensorFlow, which is a library created by Google to efficiently perform matrix calculations. \n",
    "\n",
    "We will now import some Keras modules that we will need to build our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Network\n",
    "\n",
    "We will now specify our network architecture by creating a class of type `Sequential` to represent our model. We will then add the necessary layers to our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "set_random_seed(1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape=(2,), activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `summary` method to view a description of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model\n",
    "\n",
    "Before we train the model, we need to specify what loss function to minimize, as well as what optimization method we will use to (hopefully) achieve that minimization. We can do this with the `compile` method of the `Sequential` class. We can also use compile to specify useful metrics other than the loss to be reported during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We will now train the model using the `fit` method. We specify values for the following parameters in the `fit` method below:\n",
    "* **`batch_size`** refers to the number of samples to calculate the loss on at one time. The weights will be updated after each batch. We will include the entire training set as our batch, but there can be advantages to using smaller batches. A single training loop will consider every sample in the data set, even if we are using multiple batches. \n",
    "* **`epochs`** is the number of training loops to perform. \n",
    "* **`verbose`** determines the amount of information displayed while training. If `verbose=0`, then no ouput is displayed. If `verbose=2`, then loss and any requested metrics are shown after each epoch. Setting `verbose=1` is similar to `verbose=2`, except that you will see a progress bar as well as execution time for each epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = model.fit(X, y, batch_size=300, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Training Process\n",
    "\n",
    "The output of the `fit` method contains a `history` attribute that we can use to visualize the changes in loss and accuracy during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8,4]\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(h.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(h.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiztion the Decision Region\n",
    "\n",
    "I have written a function called `plot_regions` that can be used to plot the decision regions for classification problems with two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ClassificationPlotter import plot_regions\n",
    "\n",
    "plot_regions(model, X, y, cmap='bwr_r', fig_size=(8,6), keras=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gif below shows how the classification regions changed during the process of training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Net01](Images/03_net01.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "We can used the `predict` and `predict_classes` methods of our model to generate predictions for new observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xnew = np.array([[0.2, 0.4], [0.2, 0.5], [0.2,0.6]])\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "print('Estimated probabilities of being blue:\\n', model.predict(Xnew))\n",
    "print()\n",
    "print('Predicted classes:\\n', model.predict_classes(Xnew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_regions(model, X, y, cmap='bwr', fig_size=(8,6), keras=True, display=False)\n",
    "plt.scatter(Xnew[:,0], Xnew[:,1], marker=\"D\", c='lime', edgecolor='k', s=100, zorder=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "\n",
    "We will now construct a neural network with a more complicated architecture to address the following classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "np.random.seed(1)\n",
    "plt.figure(figsize=(8,6))\n",
    "Z, w = make_circles(500, factor=0.25, noise=0.12)\n",
    "w = (w+1)%2\n",
    "plt.scatter(Z[:,0], Z[:,1], c=w, cmap='bwr_r', edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture\n",
    "\n",
    "The network we will use for this problem will have two hidden layers, each containing 8 (non-bias) neurons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Net01](Images/03_net02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Compile, and Train the Network\n",
    "\n",
    "We will now perform the same steps as before to build, compile, and train the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8,4]\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(h.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(h.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Decision Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_regions(model2, Z, w, cmap='bwr_r', fig_size=(8,6), keras=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Net02](Images/03_net02.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Znew = np.array([[0.5, 0.3], [0.5, 0.4], [0.5,0.5]])\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "\n",
    "print('Estimated probabilities of being red:\\n', model2.predict(Znew))\n",
    "print()\n",
    "print('Predicted classes:\\n', model2.predict_classes(Znew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_regions(model2, Z, w, cmap='bwr_r', fig_size=(8,6), keras=True, display=False)\n",
    "plt.scatter(Znew[:,0], Znew[:,1], marker=\"D\", c='lime', edgecolor='k', s=60, zorder=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "59ddc78617594ae2a66b9c9e95e2dd37": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
