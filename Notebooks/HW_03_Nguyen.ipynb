{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 03\n",
    "\n",
    "**Tran Nguyen**\n",
    "\n",
    "**DSCI 39001 - Neural Networks**\n",
    "\n",
    "**Due Monday, Feb. 04, 9 AM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description \n",
    "\n",
    "In this assignment, you will be tasked with designing a neural network to be trained on the \"Breast Cancer\" dataset. Information about the dataset can be found here: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages.\n",
    "\n",
    "Import the `numpy` and `matplotlib` packages. You should also import the standard classes we have used for building neural network models in keras. I recommend using the `Adam` optimizer. Finally, you should import the `set_random_seed` function from `tensorflow`, and the `train_test_split` function from `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(h5py.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing the Data\n",
    "\n",
    "The cell below will import the data from `sklearn`, and will extract the feature and label arrays. Add some code to print the shapes of these two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "bc_data = load_breast_cancer()\n",
    "X = bc_data.data\n",
    "y = bc_data.target\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data set contains 569 samples, each of which has 30 features. Each sample represents a single tumor, and the features represent measurements taken of the tumor. \n",
    "\n",
    "The cell below prints the names of the 30 features, and the names of the classes that the labels correspond to. Note that labels will be encoded as 0 or 1 within the label array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The names of the features are:\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "\n",
      "The names of the classes are: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print('The names of the features are:')\n",
    "print(bc_data.feature_names)\n",
    "\n",
    "print('\\nThe names of the classes are:', bc_data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to design and train a network that will use the 30 features as inputs, and will output a single value which will be intepreted as an estimate of the probability that the tumor is benign (Class 1). \n",
    "\n",
    "In the next cell, split `X` and `y` as follows:\n",
    "* Split `X` into `X_train`, `X_val`, and `X_test`. \n",
    "* Split `y` into `y_train`, `y_val`, and `y_test`. \n",
    "\n",
    "Split the data so that the validation and testing sets each contain 20% of the data. For the sake of reproducibility, set `random_state=1` in each call of `train_test_split`. There are a few ways to do this, but to help ensure that we all get the same results, I have provided some of the code for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size = 0.4, random_state = 1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_holdout, y_holdout, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the Model\n",
    "\n",
    "Perform the following steps in the cell below:\n",
    "1. Use `np.random.seed` and `set_random_seed` to set the Python and Tensorflow seeds to 1. \n",
    "2. Create a sequential model. You should experiment with the number of hidden layers and nodes. I recommend using the Relu activation for the hidden layers. The output layer must use a sigmoid activation. \n",
    "3. Create an optimizer object, and set the learning rate to a value of your choice. \n",
    "4. Compile your model. Specify the loss and optimizer as appropriate. Set the `metrics` parameter so that accuracy is displayed during training. \n",
    "5. Fit the model on the training data. Make sure that progress on the validation data is displayed during training. Set `verbose=2`. You can experiment with the batch_size and epochs, but please keep the number of epochs less than 200 for this problem. \n",
    "\n",
    "Your goal is to find a model that will obtain a validation accuracy of at least 93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 341 samples, validate on 114 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 7.3631 - acc: 0.3842 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 2/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 3/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 4/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 5/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 6/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 7/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 8/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 9/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 10/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 11/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 12/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 13/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 14/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 15/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 16/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 17/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 18/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 19/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 20/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 21/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 22/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 23/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 24/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 25/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 26/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 27/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 28/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 29/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 30/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 31/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 32/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 33/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 34/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 35/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 36/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 37/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 38/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 39/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 40/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 41/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 42/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 43/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 44/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 45/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 46/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 47/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 48/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 49/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 50/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 51/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 52/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 53/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 54/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 55/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 56/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 57/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 58/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 59/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 60/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 61/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 62/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 63/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 64/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 65/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 66/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 67/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 68/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 69/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 70/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 71/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 72/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 73/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 74/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 75/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 76/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 77/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 78/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 79/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 80/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 81/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 82/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 83/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 84/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 85/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 86/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 87/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 88/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 89/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 90/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 91/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 92/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 93/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 94/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 95/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 96/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 98/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 99/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Epoch 100/100\n",
      " - 0s - loss: 6.1712 - acc: 0.6129 - val_loss: 6.4329 - val_acc: 0.5965\n",
      "Validation Scores: [6.432892506582695, 0.596491231207262]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "set_random_seed(1)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(32, input_shape=(30,), activation='relu'))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.01)\n",
    "model_1.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "h = model_1.fit(X_train, y_train, batch_size=340, epochs=100, verbose=2, validation_data=(X_val, y_val))\n",
    "\n",
    "val_score = model_1.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print('Validation Scores:', val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Training Process\n",
    "\n",
    "Display two side-by-side plots that show how the loss and accuracy change during training. For each plot, label both axes, add a title, and display the legend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAEWCAYAAAB/mA49AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16685d2f358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "    \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(h.history['loss'], label='Training')\n",
    "plt.plot(h.history['val_loss'], label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(h.history['acc'], label='Training')\n",
    "plt.plot(h.history['val_acc'], label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Performance on the Test Set\n",
    "\n",
    "In the cell below, use the `evaluate` method of your model to calculate the loss and accuracy obtained by the model on the test set. Print out two lines that read as follows:\n",
    "\n",
    "    Testing Loss:     #####\n",
    "    Testing Accuracy: #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss:      4.754746503997267\n",
      "Testing Accuracy:  0.7017543880563033\n"
     ]
    }
   ],
   "source": [
    "perf_score = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Testing Loss:     ', perf_score[0])\n",
    "print('Testing Accuracy: ', perf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array called `y_pred` that contains the predicted labels for samples in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model_1.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the two cells below to display a confusion matrix and a classification report for the test set. We will explain the purpose of these reports later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 34]\n",
      " [ 0 80]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  malignant       0.00      0.00      0.00        34\n",
      "     benign       0.70      1.00      0.82        80\n",
      "\n",
      "avg / total       0.49      0.70      0.58       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRANNGUYEN.DESKTOP-M0N940V\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=bc_data.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "59ddc78617594ae2a66b9c9e95e2dd37": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
